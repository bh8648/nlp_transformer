{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f32f49c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'nlp-with-transformers' already exists and is not an empty directory.\n",
      "/home/jj/github/NLP/nlp-with-transformers\n",
      "⏳ Installing base requirements ...\n",
      "✅ Base requirements installed!\n",
      "Using transformers v4.31.0\n",
      "Using datasets v2.13.1\n",
      "Using accelerate v0.21.0\n",
      "Using sentencepiece v0.1.99\n",
      "Using sacrebleu v2.3.1\n",
      "Using rouge_score\n",
      "Using nltk v3.8.1\n",
      "Using py7zr v0.20.5\n"
     ]
    }
   ],
   "source": [
    "# 코랩을 사용하지 않으면 다음 코드를 주석 처리하세요.\n",
    "!git clone https://github.com/rickiepark/nlp-with-transformers.git\n",
    "%cd nlp-with-transformers\n",
    "from install import *\n",
    "install_requirements(chapter=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0bd26b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"]=\"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b99d1016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getcwd())\n",
    "# os.chdir(\"/home/jj/github/NLP/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe565bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0035ff23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05dd57b",
   "metadata": {},
   "source": [
    "# 요약\n",
    "요약은 입력과 출력이 텍스트인 고전적인 시퀀스-투-시퀀스(seq-2-seq) 작업이다.  \n",
    "요약에는 인코더-디코더 트랜스포머가 잘 맞다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42624036",
   "metadata": {},
   "source": [
    "#### 인코더-디코더 모델을 만들어 여러 사람이 주고받은 대화를 간결하게 요약하기 전, 요약에 사용하는 대표적인 데이터셋 CNN/DailyMail 말뭉치를 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6453249",
   "metadata": {},
   "source": [
    "# 6.1 CNN/DailyMail 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6919919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d99046a5598042e795aa867a00d18460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c7d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성: ['article', 'highlights', 'id']\n"
     ]
    }
   ],
   "source": [
    "print(f\"특성: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24299e5e",
   "metadata": {},
   "source": [
    "이 데이터셋은 세 가지 특성이 존재한다.  \n",
    "뉴스기사를 담은 article, 요약에 해당하는 highlights, 기사의 고유 아이디 id다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d6152c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 (초반 500개 문자 발췌, 총 길이: 4051):\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their\n",
      "experiences in covering news and analyze the stories behind the events. Here,\n",
      "Soledad O'Brien takes users inside a jail where many of the inmates are mentally\n",
      "ill. An inmate housed on the \"forgotten floor,\" where many mentally ill inmates\n",
      "are housed in Miami before trial. MIAMI, Florida (CNN) -- The ninth floor of the\n",
      "Miami-Dade pretrial detention facility is dubbed the \"forgotten floor.\" Here,\n",
      "inmates with the most s\n",
      "\n",
      "요약 (길이: 281):\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[\"train\"][1]\n",
    "print(f\"\"\"기사 (초반 500개 문자 발췌, 총 길이: {len(sample[\"article\"])}):\"\"\")\n",
    "print(sample[\"article\"][:500])\n",
    "print(f\"\\n요약 (길이: {len(sample['highlights'])}):\")\n",
    "print(sample[\"highlights\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578d0df",
   "metadata": {},
   "source": [
    "기사가 요약에 비해 매우 긴 경우도 존재한다. (해당 예시의 경우 17배나 차이가 난다.)  \n",
    "대부분 트랜스포머 모델의 문맥크기가 몇 단락에 해당하는 분량인 1,000개 토큰 정도로 제한되므로, 긴 기사는 트랜스포머 모델에 문제를 일으킨다.  \n",
    "### 이를 처리하는 표준적이면서 가장 단순한 방법은 모델의 문맥 크기에 맞춰 텍스트를 자르는 것이다.\n",
    "#### 텍스트 끝부분에 중요한 정보가 있다면 사라지겠지만, 이는 모델 구조의 제약으로 생기는 불가피한 선택이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459a2e7",
   "metadata": {},
   "source": [
    "# 6.2 텍스트 요약 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e494793b",
   "metadata": {},
   "source": [
    "요약 작업에 많이 사용되는 트랜스포머 모델 몇 가지를 알아보자.  \n",
    "살펴볼 모델 구조는 최대 입력 크기가 각각 다르지만 동일한 입력을 사용하고 출력을 비교하기 위해 입력 텍스트를 2,000자로 제한하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01dd3d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = dataset['train'][1]['article'][:2000]\n",
    "# 딕셔너리에 각 모델이 생성한 요약을 저장할 예정.\n",
    "summaries = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8545660d",
   "metadata": {},
   "source": [
    "#### 요약에서는 관례적으로 요약 문장을 줄바꿈으로 나눈다.  \n",
    "마침표마다 그 뒤에 줄바꿈 토큰을 추가해도 되지만 그러면 'U.S.'나 'U.N.' 같은 문자열을 처리하지 못한다.  \n",
    "#### NLTK(Natural Language Toolkit) 패키지에는 문장의 종결과 약어에 등장하는 구두점을 구별하는 더 정교한 알고리즘이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2ebd33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jj/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26bd44c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The U.S. are a country.', 'The U.N. is an organization.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
    "sent_tokenize(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb9fccf",
   "metadata": {},
   "source": [
    "## 6.2.1 요약 기준 모델\n",
    "기사를 요약하는 일반적인 기준 모델(baseline)은 단순히 기사에서 맨 처음 문장 세 개를 선택하는 것이다. 이런 기준 모델은 NLTK 문장 토크나이저로 쉽게 구현할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcebc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c103e21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8acea9",
   "metadata": {},
   "source": [
    "## 6.2.2 GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db2a1ef",
   "metadata": {},
   "source": [
    "gpt-2 모델은 입력 텍스트 뒤에 'TL;DR'을 추가해 요약을 생성하는 기능이 있다.  \n",
    "(TL;DR -> Toll long; didn't read (너무 길어 읽지 않았다)는 문구의 약어)  \n",
    "\"TL;DR\"은 레딧 같은 사이트에서 긴 포스트를 짧게 요약할 때 종종 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0721d2",
   "metadata": {},
   "source": [
    "트랜스포머스의 pipeline() 함수로 원본 논문의 방식을 재현하며 요약 작업을 실험해보자.  \n",
    "#### 텍스트 생성 파이프라인을 만들고 대용량 GPT-2 모델을 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "683dbaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "482fe704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 코랩의 경우 gpt2-xl을 사용하면 메모리 부족 에러가 발생합니다.\n",
    "# 대신 \"gpt\" 또는 \"gpt2-large\"로 지정하거나 코랩 프로를 사용하세요.\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"gpt2-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3a00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
    "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces = True)\n",
    "summaries['gpt2'] = \"\\n\".join(\n",
    "    sent_tokenize(pipe_out[0]['generated_text'][len(gpt2_query) :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee7dc66",
   "metadata": {},
   "source": [
    "나중의 비교를 위해 출력에서 입력 텍스트의 다음 부분을 요약으로 추출해 파이썬 딕셔너리에 저장한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cdf853",
   "metadata": {},
   "source": [
    "## 6.2.3 T5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ad56b0",
   "metadata": {},
   "source": [
    "T5의 개발자들은 NLP에서 포괄적인 전이 학습 연구를 수행해 모든 작업을 텍스트-투-텍스트 작업으로 구성하는 범용의 트랜스포머 아키텍처를 만들었다.  \n",
    "T5 체크포인트는 요약을 포함해 여러 작업에서 (마스킹된 단어를 재구성하기 위한) 비지도 학습 데이터와 지도 학습 데이터를 섞은 데이터로 훈련됐다.  \n",
    "따라서 미세 튜닝 없이 이 체크포인트를 사전 훈련에 썼던 것과 동일한 프롬프트를 사용해 바로 요약에 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3eb2a3",
   "metadata": {},
   "source": [
    "문서 요약에 사용할 모델의 입력 포맷은 \"summarize: \\<Article>\"이고, 번역에 사용할 입력 포맷은 \"translate English to German: \\<TEXT>\"다.  \n",
    "T5의 텍스트-투-텍스트 프레임워크에는 '번역'과 '요약' 작업 말고도 'CoLA(linguistic acceptability)'와 'STSB(semantic similarity)' 작업이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ea8493",
   "metadata": {},
   "source": [
    "#### 요약을 위해 pipeline() 함수로 T5를 로드한다.\n",
    "이 함수는 입력을 텍스트-투-텍스트 포맷으로 처리하므로 앞에 \"summarize\"를 붙일 필요가 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33567036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/anaconda3/envs/NLP/lib/python3.8/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-large automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"t5-large\") # 책에서는 't5-large'사용\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fa8b77",
   "metadata": {},
   "source": [
    "## 6.2.4 BART"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ba9afe",
   "metadata": {},
   "source": [
    "BART도 인코더-디코더를 사용하는 모델로, 손상된 입력을 재구성하도록 훈련됐다.  \n",
    "#### 이를 위해 BERT와 GPT-2의 사전 훈련 방식을 결합한다.\n",
    "여기서는 특별히 CNN/DailyMail 데이터셋에 미세 튜닝된 facebook/bart-large-ccn 체크포인트를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "903fcd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "pipe_out = pipe(sample_text)\n",
    "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc70805",
   "metadata": {},
   "source": [
    "## 6.2.5 PEGASUS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10197dcc",
   "metadata": {},
   "source": [
    "PEGASUS는 BART와 마찬가지로 인코더-디코더 트랜스포머다.  \n",
    "이 모델은 여러 문장으로 구성된 텍스트에서 마스킹된 문장을 예측하는 사전 훈련 목표로 훈련됐다.  \n",
    "논문의 저자들은 사전 훈련 목표가 후속 작업에 가까울수록 더 효과적이라고 주장한다.  \n",
    "#### 일반적인 언어 모델링보다 요약에 특화된 사전 훈련 목표를 찾기 위해 대규모 말뭉치에서( 내용 중복을 측정하는 요약 평가 지표를 사용해) 주변 문단의 내용을 대부분 담은 문장을 자동으로 식별했다.\n",
    "이런 문장을 재구성하도록 PEGASUS 모델을 사전 훈련해 최고 수준의 텍스트 요약 모델을 얻었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "378ef544",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0346dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_out = pipe(sample_text)\n",
    "# 이 모델은 줄바꿈하는 특수 토큰이 있으므로 sent_tokenize() 함수를 사용할 필요가 없다.\n",
    "summaries['pegasus'] = pipe_out[0]['summary_text'].replace(\" .<n>\", \".\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c93eb3",
   "metadata": {},
   "source": [
    "# 6.3 요약 결과 비교하기\n",
    "가장 처음의 GPT-2 모델은 데이터셋에서 전혀 훈련되지 않았다는 점을 기억해둘 것.  \n",
    "T5 모델은 여러 작업 중의 하나로 이 작업을 위해 미세 튜닝됐다.  \n",
    "BART와 PEGASUS 두 모델은 이 작업만을 위해 미세튜닝 됐다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad6abe",
   "metadata": {},
   "source": [
    "#### 네 모델이 생성한 요약결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9abd7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GROUND TRUTH\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"\n",
      "Judge Steven Leifman says most are there as a result of \"avoidable felonies\"\n",
      "While CNN tours facility, patient shouts: \"I am the son of the president\"\n",
      "Leifman says the system is unjust and he's fighting for change .\n",
      "\n",
      "BASELINE\n",
      "Editor's note: In our Behind the Scenes series, CNN correspondents share their\n",
      "experiences in covering news and analyze the stories behind the events.\n",
      "Here, Soledad O'Brien takes users inside a jail where many of the inmates are\n",
      "mentally ill. An inmate housed on the \"forgotten floor,\" where many mentally ill\n",
      "inmates are housed in Miami before trial.\n",
      "MIAMI, Florida (CNN) -- The ninth floor of the Miami-Dade pretrial detention\n",
      "facility is dubbed the \"forgotten floor.\"\n",
      "\n",
      "GPT2\n",
      "-- We visited the jail where mentally ill people are locked up and did an\n",
      "investigation on what jailers really think about the mentally ill\n",
      "-- Mentally ill people end up in the court system and are often imprisoned on\n",
      "drug charges\n",
      "-- Most of the mentally ill people that go to court end up in court without\n",
      "proper therapy\n",
      "-- Jailers claim that the mentally ill inmates are \"more\n",
      "\n",
      "T5\n",
      "mentally ill inmates are housed on the ninth floor of a florida jail .\n",
      "most face drug charges or charges of assaulting an officer .\n",
      "judge says arrests often result from confrontations with police .\n",
      "one-third of all people in Miami-dade county jails are mental ill .\n",
      "\n",
      "BART\n",
      "Mentally ill inmates are housed on the \"forgotten floor\" of Miami-Dade jail.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "Judge Steven Leifman says the arrests often result from confrontations with\n",
      "police.\n",
      "He says about one-third of all people in the county jails are mentally ill.\n",
      "\n",
      "PEGASUS\n",
      "Mentally ill inmates in Miami are housed on the \"forgotten floor\"<n>The ninth\n",
      "floor is where they're held until they're ready to appear in court.\n",
      "Most often, they face drug charges or charges of assaulting an officer.\n",
      "They end up on the ninth floor severely mentally disturbed .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GROUND TRUTH\")\n",
    "print(dataset['train'][1]['highlights'])\n",
    "print(\"\")\n",
    "\n",
    "for model_name in summaries:\n",
    "    print(model_name.upper())\n",
    "    print(summaries[model_name])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337dbd22",
   "metadata": {},
   "source": [
    "이제 제품환경에 어떤 모델을 사용할지 결정해보자.  \n",
    "#### 지표를 하나 정의하고 특정 벤치마크 데이터셋에서 모든 모델을 평가해서 성능이 최고인 모델을 선택하는 것이 이상적인 방법이다.\n",
    "하지만 어떤 평가지표를 써야할까 -> 정확도, 재현율, 정밀도 같은 표준 지표는 이 작업에 적용하기 쉽지않다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75dd07",
   "metadata": {},
   "source": [
    "# 6.4 생성된 텍스트 품질 평가하기\n",
    "평가 지표 -> 모델을 훈련할 때만이 아니라 나중에 제품 환경에서도 모델 성능을 평가하기 때문에 중요.  \n",
    "평가 지표가 나쁘면 모델의 성능 저하를 눈치 채지 못하고, 평가 지표가 비즈니스 목표에 맞지 않으면 어떤 가치도 창출하지 못함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e846768b",
   "metadata": {},
   "source": [
    "### 생성된 텍스트를 평가하는데 가장 널리 사용되는 두 지표는 BLEU와 ROUGE다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f512a44",
   "metadata": {},
   "source": [
    "## 6.4.1 BLEU\n",
    "https://oreil.ly/nMXRh 에서는 BLEU의 단점을 잘 설명해두었다.  \n",
    "BLEU-4 score가 많이 쓰이며, 토큰화 단계를 내재화한 SacreBLEU가 벤치마킹에서 선호되는 지표다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6f0a0cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7673/3482725883.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  bleu_metric = load_metric(\"sacrebleu\")\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_metric\n",
    "bleu_metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe74de4",
   "metadata": {},
   "source": [
    "bleu_metric 객체는 Metric 클래스의 인스턴스로 하나의 수집기(aggregator)처럼 작동한다.  \n",
    "add() 메서드에 샘플 하나를 추가하거나 add_batch() 메서드로 배치 전체를 추가한다.  \n",
    "평가하려는 샘플을 모두 추가한 다음 compute() 메서드를 호출하면 지표가 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8dc459",
   "metadata": {},
   "source": [
    "이 메서드는 몇 개의 값으로 구성된 딕셔너리를 반환한다.  \n",
    "(각 n-gram에 대한 정밀도, 길이 페널티, 최종 BLEU 점수 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "020e2afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[2, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[6, 5, 4, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Value\n",
       "score                          0.0\n",
       "counts                [2, 0, 0, 0]\n",
       "totals                [6, 5, 4, 3]\n",
       "precisions  [33.33, 0.0, 0.0, 0.0]\n",
       "bp                             1.0\n",
       "sys_len                          6\n",
       "ref_len                          6"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be92f52",
   "metadata": {},
   "source": [
    "BLEU 점수는 여러 참조 번역이 있는 경우에도 계산된다.  \n",
    "이 때문에 reference 매개변수에 리스트를 전달한다.  \n",
    "BLEU는 정밀도 계산을 조금 바꿔 n-gram이 하나도 없을 때 최종점수가 0이 되는 경우를 방지한다.  \n",
    "이를 위한 방법으로 분자에 상수 값을 추가한다.  \n",
    "이렇게 하면 n-gram이 없어도 점수가 0이되지 않는다. (이 값을 설명하기 위해 smooth_value=0로 지정해 해당 기능을 껐다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a86ba2",
   "metadata": {},
   "source": [
    "※ smooth_method가 'floor'이면 smooth_value의 기본값이 0.1이고, n-gram이 없을 경우 분자로 0.1을 사용한다.  \n",
    "smoot_method가 'add-k'이면 smooth_value의 기본값이 1이고, n-gram이 없을 경우 분모와 분자에 1이 더해진다.  \n",
    "smooth_method의 기본값은 'exp'이며 smooth_value를 사용하지 않고, n-gram이 없을 때마다 2의 거듭제곱을 누적해 분모에 곱한 역수를 계산한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060ca3ec",
   "metadata": {},
   "source": [
    "### 1-gram의 정밀도는 실제로 2/6이다. 반면 2/3/4-gram의 정밀도는 모두 0이다.\n",
    "### 따라서 기하 평균이 0이 되므로 BLEU 점수도 0이 된다.\n",
    "\n",
    "(counts와 bp 같은 개별 지표의 자세한 내용은 SacreBLEU 저장소 https://oreil.ly/kiZPl 를 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "161a6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>57.893007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>counts</th>\n",
       "      <td>[5, 3, 2, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>totals</th>\n",
       "      <td>[5, 4, 3, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precisions</th>\n",
       "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>0.818731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sys_len</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ref_len</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Value\n",
       "score                        57.893007\n",
       "counts                    [5, 3, 2, 1]\n",
       "totals                    [5, 4, 3, 2]\n",
       "precisions  [100.0, 75.0, 66.67, 50.0]\n",
       "bp                            0.818731\n",
       "sys_len                              5\n",
       "ref_len                              6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정밀도가 높은 예시\n",
    "\n",
    "bleu_metric.add(\n",
    "    prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
    "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
    "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b63d5",
   "metadata": {},
   "source": [
    "예측에 있는 1-gram은 모두 맞지만 다른 정밀도 점수를 보면 틀린 예측도 있음을 알 수 있다.  \n",
    "4-gram은 [\"the\", \"cat\", \"is\", \"on\"]과 [\"cat\", \"is\", \"on\", \"mat\"] 두 개다.  \n",
    "두 번째를 맞추지 못했으므로 4-gram 정밀도는 0.5가 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a6f73",
   "metadata": {},
   "source": [
    "### BLEU 점수는 텍스트 평가에 널리 사용된다.  \n",
    "### 가능하고 적합한 단어를 모두 포함하는 번역보다 정확한 번역이 선호되기 때문에 특히 기계 번역에 많이 쓰인다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6b5c9",
   "metadata": {},
   "source": [
    "이와 상황이 다른 요약 같은 애플리케이션이 있다.  \n",
    "이때는 중요한 정보가 생성된 텍스트에 모두 포함되어야 하므로 높은 재현율이 선호된다.\n",
    "이런 작업에는 주로 ROUGE가 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de8af48",
   "metadata": {},
   "source": [
    "## 6.4.2 ROUGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cac31b",
   "metadata": {},
   "source": [
    "데이터셋 구현은 두 종류의 ROUGE 점수를 계산한다.  \n",
    "하나는 문장마다 점수를 계산해서 요약에 대해 평균한 점수(ROUGE-L)이고,  \n",
    "다른 하나는 전체 요약에 대해 계산한 점수(ROUGE-Lsum)이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25fed47",
   "metadata": {},
   "source": [
    "이 측정 지표는 이렇게 로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67572744",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8a4cf7",
   "metadata": {},
   "source": [
    "위에서 여러 모델의 요약을 이미 생성했으니 이 지표로 요약을 비교해보자.  \n",
    "모델이 생성한 모든 요약에 ROUGE 점수를 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "563bfa7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.145161</td>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt2</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.156522</td>\n",
       "      <td>0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t5</th>\n",
       "      <td>0.382979</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.255319</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bart</th>\n",
       "      <td>0.475248</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.316832</td>\n",
       "      <td>0.415842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pegasus</th>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.206186</td>\n",
       "      <td>0.282828</td>\n",
       "      <td>0.323232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.365079  0.145161  0.206349   0.285714\n",
       "gpt2      0.260870  0.053097  0.156522   0.260870\n",
       "t5        0.382979  0.130435  0.255319   0.382979\n",
       "bart      0.475248  0.222222  0.316832   0.415842\n",
       "pegasus   0.323232  0.206186  0.282828   0.323232"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference = dataset[\"train\"][1][\"highlights\"]\n",
    "records = []\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "for model_name in summaries:\n",
    "    rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
    "    score = rouge_metric.compute()\n",
    "    rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "    records.append(rouge_dict)\n",
    "pd.DataFrame.from_records(records, index=summaries.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c33bea2",
   "metadata": {},
   "source": [
    "데이터셋에 있는 ROUGE 지표는 신뢰구간 confidence interval(기본적으로 백분위수 9와 95 사이)도 계산한다.  \n",
    "mid 속성에 중앙값이 저장되고 low와 high 속성으로 구간의 양 끝 값을 추출한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bad20f",
   "metadata": {},
   "source": [
    "단일 샘플만 보았으므로 이 결과를 크게 신뢰하기는 어렵지만, 한 샘플에 대한 요약 품질을 비교할 수 있다.  \n",
    "이 표에서 GPT-2의 성능이 가장 낮다. 이 모델만 요약을 위해 명시적으로 훈련되지 않았으니 그럴 만하다.  \n",
    "놀라운 부분은 처음 세 문장을 요약으로 사용한 간단한 기준 모델이 파라미터가 약 10억 개인 트랜스포머 모델에 비해 그다지 뒤떨어 지지 않는다는 점이다.  \n",
    "#### ROUGE 점수가 높을수록 좋다. 해당 결과에서는 bart가 가장 좋게 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e488bbb",
   "metadata": {},
   "source": [
    "# 6.5 CNN/DailyMail 데이터셋에서 PEGASUS 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ba320cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479e7a68e396402e91ccb4fec958a83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이 셀은 노트북 중간부터 실행하기 위한 것.\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# \"cnn_dailymail\" 데이터셋 다운로드 에러가 발생할 경우 대신 \"ccdv/cnn_dailymail\"을 사용\n",
    "dataset = load_dataset(\"cnn_dailymail\", version='3.0.0')\n",
    "rouge_metric = load_metric(\"rouge\", cache_dir=None)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c58154a",
   "metadata": {},
   "source": [
    "#### 처음 세 문장을 사용하는 기준 모델의 성능부터 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d37e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summaries_baseline(dataset, metric,\n",
    "                               column_text=\"article\",\n",
    "                               column_summary=\"highlights\"):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
    "    metric.add_batch(predictions=summaries,\n",
    "                    references=dataset[column_summary])\n",
    "    score = metric.compute()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0a318",
   "metadata": {},
   "source": [
    "데이터셋의 테스트 세트는 대략 10,000개의 샘플로 구성되었다.  \n",
    "생성되는 모든 토큰이 모델의 정방향 패스를 거쳐야하며, 샘플마다 100개 토큰을 생성하기 위해 필요한 정방향 패스의 횟수는 백만 번이다.  \n",
    "빔 서치를 사용할 경우 이 수치에 빔 크기를 곱해야 한다.  \n",
    "계산을 빠르게 마치기 위해 테스트 세트에서 1,000개를 샘플링해 평가해보자.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ce503d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "      <th>rougeLsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.389276</td>\n",
       "      <td>0.171296</td>\n",
       "      <td>0.245061</td>\n",
       "      <td>0.354239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rouge1    rouge2    rougeL  rougeLsum\n",
       "baseline  0.389276  0.171296  0.245061   0.354239"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame.from_dict(rouge_dict, orient='index', columns=[\"baseline\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea794815",
   "metadata": {},
   "source": [
    "#### 이제 PEGASUS 모델을 평가할 함수를 구현해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83b8d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def chunks(list_of_elements, batch_size):\n",
    "    \"\"\"list_of_elements로부터 batch_size 크기의 청크를 연속적으로 생성합니다\"\"\"\n",
    "    for i in range(0, len(list_of_elements), batch_size):\n",
    "        yield list_of_elements[i : i + batch_size]\n",
    "\n",
    "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer,\n",
    "                              batch_size=16, device=device,\n",
    "                              column_text=\"article\",\n",
    "                              column_summary=\"highlights\"):\n",
    "    article_batches = list(chunks(dataset[column_text], batch_size))\n",
    "    target_batches = list(chunks(dataset[column_summary], batch_size))\n",
    "    \n",
    "    for article_batch, target_batch in tqdm(\n",
    "        zip(article_batches, target_batches), total=len(article_batches)):\n",
    "        \n",
    "        inputs = tokenizer(article_batch, max_length=1024, truncation=True,\n",
    "                          padding=\"max_length\", return_tensors=\"pt\")\n",
    "        \n",
    "        summaries = model.generate(input_ids=inputs['input_ids'].to(device),\n",
    "                                  attention_mask=inputs['attention_mask'].to(device),\n",
    "                                  length_penalty=0.8, num_beams=8, max_length=128)\n",
    "\n",
    "        decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True,\n",
    "                                             clean_up_tokenization_spaces=True)\n",
    "                            for s in summaries]\n",
    "        decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
    "        metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
    "    \n",
    "    score = metric.compute()\n",
    "    return score    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80b4ce4",
   "metadata": {},
   "source": [
    "1) 먼저 데이터셋을 동시에 처리하기 위해 작은 배치로 나눔\n",
    "2) 그다음 각 배치의 입력 샘플을 토큰화하고 generate() 함수에 전달해 빔 서치로 요약을 생성. (논문에 언급된 것과 동일한 생성 매개변수 사용)\n",
    "3) 길이 패널티 매개변수는 모델이 매우 긴 시퀀스를 생성하지 않도록 한다.\n",
    "4) 마지막으로 생성된 텍스트를 디코딩하고, \\<n> 토큰을 공백으로 바꾸고, 디코딩된 토큰과 참조 텍스트를 지표에 추가한다.\n",
    "5) 마침내 ROUGE 점수를 계산하고 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac19c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b0d086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2553dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = evaluate_summaries_pegasus(test_sampled, rouge_metric,\n",
    "#                                    model, tokenizer, batch_size=4)\n",
    "# rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "# pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e081f1f",
   "metadata": {},
   "source": [
    "#### 중요한 점은 손실과 각 토큰의 정확도가 ROUGE 점수와 일정 수준 관련성이 없다는 것이다.  \n",
    "#### 손실은 디코딩 전략과 관련이 없지만, ROUGE 점수는 디코딩 전략과 밀접하게 관련된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8037278d",
   "metadata": {},
   "source": [
    "ROUGE와 BLEU가 손실이나 정확도보다 사람의 판단과 더 밀접하므로 여기에 초점을 맞추고 텍스트 생성 모델을 만들 때 디코딩 전략을 주의 깊게 탐색하고 선택해야 한다.  \n",
    "하지만 이런 지표가 완벽하지는 않으므로 항상 사람의 판단도 고려할 필요가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921ef03b",
   "metadata": {},
   "source": [
    "#### 평가 함수를 마련했으니, 이제 요약을 위한 모델을 직접 훈련해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b364b",
   "metadata": {},
   "source": [
    "# 6.6 요약 모델 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064adb4c",
   "metadata": {},
   "source": [
    "삼성이 만든 SAMSum 데이터셋 사용.  \n",
    "https://oreil.ly/n1ggq  \n",
    "이 데이터셋은 대화와 이에 대한 짧은 요약으로 구성된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aea45b",
   "metadata": {},
   "source": [
    "기업에서 이런 대화는 고객과 지원 센터의 상호작용을 나타낸다.  \n",
    "따라서 정확한 요약을 생성하면 고객 서비스를 개선하고 고객 요청에 나타난 보편적인 패턴을 감지할 수 있다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76e2ba85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6055e1038c49bb9cfdb244cc726c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할 크기: [14732, 819, 818]\n",
      "특성: ['id', 'dialogue', 'summary']\n",
      "\n",
      "대화:\n",
      "Hannah: Hey, do you have Betty's number?\n",
      "Amanda: Lemme check\n",
      "Hannah: <file_gif>\n",
      "Amanda: Sorry, can't find it.\n",
      "Amanda: Ask Larry\n",
      "Amanda: He called her last time we were at the park together\n",
      "Hannah: I don't know him well\n",
      "Hannah: <file_gif>\n",
      "Amanda: Don't be shy, he's very nice\n",
      "Hannah: If you say so..\n",
      "Hannah: I'd rather you texted him\n",
      "Amanda: Just text him 🙂\n",
      "Hannah: Urgh.. Alright\n",
      "Hannah: Bye\n",
      "Amanda: Bye bye\n",
      "\n",
      "Summary:\n",
      "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact\n",
      "Larry.\n"
     ]
    }
   ],
   "source": [
    "dataset_samsum = load_dataset(\"samsum\")\n",
    "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
    "\n",
    "print(f\"분할 크기: {split_lengths}\")\n",
    "print(f\"특성: {dataset_samsum['train'].column_names}\")\n",
    "print(\"\\n대화:\")\n",
    "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
    "print(\"\\nSummary:\")\n",
    "print(dataset_samsum[\"test\"][0][\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "74181afa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 14732\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 819\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'dialogue', 'summary'],\n",
       "        num_rows: 818\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_samsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9677354",
   "metadata": {},
   "source": [
    "해당 대화에는 이모지와 GIF를 위한 플레이스홀더(placeholder)가 포함됐다.  \n",
    "dialogue 필드는 전체 텍스트를 담고 있고 summary는 대화의 요약이다.\n",
    "#### CNN/DailyMail 데이터셋에서 미세 튜닝한 모델이 같은 작업을 수행할 수 있을지 알아보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d96ce25",
   "metadata": {},
   "source": [
    "## 6.6.1 SAMSum에서 PEGASUS 평가하기\n",
    "#### 먼저 PEGASUS로 요약 파이프라인을 실행하여 어떻게 출력하는지 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08a9ea23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약:\n",
      "Amanda: Ask Larry Amanda: He called her last time we were at the park together.\n",
      "Hannah: I'd rather you texted him.\n",
      "Amanda: Just text him .\n"
     ]
    }
   ],
   "source": [
    "pipe_out = pipe(dataset_samsum['test'][0]['dialogue'])\n",
    "print(\"요약:\")\n",
    "print(pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea31c6",
   "metadata": {},
   "source": [
    "모델이 대화에서 핵심 문장을 추출해 요약하려는 것 같다.  \n",
    "CNN/DailyMail 데이터셋에는 비교적 잘 맞았겠지만 SAMSum의 요약은 더 추상적이다.  \n",
    "#### 테스트 세트에서 ROUGE 평가를 수행해 이를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "02d9cb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = evaluate_summaries_pegasus(dataset_samsum['test'], rouge_metric,\n",
    "#                                    model, tokenizer, column_text=\"dialogue\",\n",
    "#                                   column_summary=\"summary\", batch_size=4)\n",
    "# rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "# pd.DataFrame(rouge_dict, index=[\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64bece3",
   "metadata": {},
   "source": [
    "결과가 좋지는 않지만, CNN/DailyMail 데이터셋이 SAMSum과 크게 다르기 떄문에 어느 정도 예상할만한 결과다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb6257f",
   "metadata": {},
   "source": [
    "#### 훈련 전에 평가 파이프라인을 준비하면 두 가지 이점이 있다.\n",
    "### 훈련이 성공적인지 바로 평가가 가능해졌고 기준점이 세워진 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d281078",
   "metadata": {},
   "source": [
    "이 데이터셋에서 모델을 미세튜닝하면 ROUGE 점수가 바로 향상되어야 한다.  \n",
    "그렇지 않으면 훈련 과정에 문제가 있는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc807cd7",
   "metadata": {},
   "source": [
    "## 6.6.2 PEGASUS 미세 튜닝하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba750cc",
   "metadata": {},
   "source": [
    "훈련을 위해 데이터를 처리하기 전, 입력과 출력 길이의 분포를 간단히 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5aebba41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"707.34375pt\" height=\"237.92925pt\" viewBox=\"0 0 707.34375 237.92925\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-07-20T18:23:11.960541</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 237.92925 \n",
       "L 707.34375 237.92925 \n",
       "L 707.34375 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 60.35375 196.50175 \n",
       "L 372.01875 196.50175 \n",
       "L 372.01875 24.14175 \n",
       "L 60.35375 24.14175 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 74.520341 196.50175 \n",
       "L 88.686932 196.50175 \n",
       "L 88.686932 72.09733 \n",
       "L 74.520341 72.09733 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 88.686932 196.50175 \n",
       "L 102.853523 196.50175 \n",
       "L 102.853523 32.349369 \n",
       "L 88.686932 32.349369 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 102.853523 196.50175 \n",
       "L 117.020114 196.50175 \n",
       "L 117.020114 86.515321 \n",
       "L 102.853523 86.515321 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 117.020114 196.50175 \n",
       "L 131.186705 196.50175 \n",
       "L 131.186705 120.551236 \n",
       "L 117.020114 120.551236 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 131.186705 196.50175 \n",
       "L 145.353295 196.50175 \n",
       "L 145.353295 151.317497 \n",
       "L 131.186705 151.317497 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 145.353295 196.50175 \n",
       "L 159.519886 196.50175 \n",
       "L 159.519886 170.265732 \n",
       "L 145.353295 170.265732 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 159.519886 196.50175 \n",
       "L 173.686477 196.50175 \n",
       "L 173.686477 180.586808 \n",
       "L 159.519886 180.586808 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 173.686477 196.50175 \n",
       "L 187.853068 196.50175 \n",
       "L 187.853068 188.229132 \n",
       "L 173.686477 188.229132 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 187.853068 196.50175 \n",
       "L 202.019659 196.50175 \n",
       "L 202.019659 192.444228 \n",
       "L 187.853068 192.444228 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 202.019659 196.50175 \n",
       "L 216.18625 196.50175 \n",
       "L 216.18625 193.586637 \n",
       "L 202.019659 193.586637 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 216.18625 196.50175 \n",
       "L 230.352841 196.50175 \n",
       "L 230.352841 195.12298 \n",
       "L 216.18625 195.12298 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 230.352841 196.50175 \n",
       "L 244.519432 196.50175 \n",
       "L 244.519432 195.556308 \n",
       "L 230.352841 195.556308 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 244.519432 196.50175 \n",
       "L 258.686023 196.50175 \n",
       "L 258.686023 196.107816 \n",
       "L 244.519432 196.107816 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 258.686023 196.50175 \n",
       "L 272.852614 196.50175 \n",
       "L 272.852614 196.225996 \n",
       "L 258.686023 196.225996 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 272.852614 196.50175 \n",
       "L 287.019205 196.50175 \n",
       "L 287.019205 196.422963 \n",
       "L 272.852614 196.422963 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 287.019205 196.50175 \n",
       "L 301.185795 196.50175 \n",
       "L 301.185795 196.422963 \n",
       "L 287.019205 196.422963 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 301.185795 196.50175 \n",
       "L 315.352386 196.50175 \n",
       "L 315.352386 196.462357 \n",
       "L 301.185795 196.462357 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 315.352386 196.50175 \n",
       "L 329.518977 196.50175 \n",
       "L 329.518977 196.462357 \n",
       "L 315.352386 196.462357 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 329.518977 196.50175 \n",
       "L 343.685568 196.50175 \n",
       "L 343.685568 196.50175 \n",
       "L 329.518977 196.50175 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 343.685568 196.50175 \n",
       "L 357.852159 196.50175 \n",
       "L 357.852159 196.462357 \n",
       "L 343.685568 196.462357 \n",
       "z\n",
       "\" clip-path=\"url(#pb0c5c056da)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"m884eb71afe\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"74.24869\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(70.43119 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"128.578857\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 200 -->\n",
       "      <g transform=\"translate(117.126357 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"182.909023\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 400 -->\n",
       "      <g transform=\"translate(171.456523 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \n",
       "L 825 1625 \n",
       "L 2419 1625 \n",
       "L 2419 4116 \n",
       "z\n",
       "M 2253 4666 \n",
       "L 3047 4666 \n",
       "L 3047 1625 \n",
       "L 3713 1625 \n",
       "L 3713 1100 \n",
       "L 3047 1100 \n",
       "L 3047 0 \n",
       "L 2419 0 \n",
       "L 2419 1100 \n",
       "L 313 1100 \n",
       "L 313 1709 \n",
       "L 2253 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"237.23919\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 600 -->\n",
       "      <g transform=\"translate(225.78669 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \n",
       "Q 1688 2584 1439 2293 \n",
       "Q 1191 2003 1191 1497 \n",
       "Q 1191 994 1439 701 \n",
       "Q 1688 409 2113 409 \n",
       "Q 2538 409 2786 701 \n",
       "Q 3034 994 3034 1497 \n",
       "Q 3034 2003 2786 2293 \n",
       "Q 2538 2584 2113 2584 \n",
       "z\n",
       "M 3366 4563 \n",
       "L 3366 3988 \n",
       "Q 3128 4100 2886 4159 \n",
       "Q 2644 4219 2406 4219 \n",
       "Q 1781 4219 1451 3797 \n",
       "Q 1122 3375 1075 2522 \n",
       "Q 1259 2794 1537 2939 \n",
       "Q 1816 3084 2150 3084 \n",
       "Q 2853 3084 3261 2657 \n",
       "Q 3669 2231 3669 1497 \n",
       "Q 3669 778 3244 343 \n",
       "Q 2819 -91 2113 -91 \n",
       "Q 1303 -91 875 529 \n",
       "Q 447 1150 447 2328 \n",
       "Q 447 3434 972 4092 \n",
       "Q 1497 4750 2381 4750 \n",
       "Q 2619 4750 2861 4703 \n",
       "Q 3103 4656 3366 4563 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"291.569356\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 800 -->\n",
       "      <g transform=\"translate(280.116856 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \n",
       "Q 1584 2216 1326 1975 \n",
       "Q 1069 1734 1069 1313 \n",
       "Q 1069 891 1326 650 \n",
       "Q 1584 409 2034 409 \n",
       "Q 2484 409 2743 651 \n",
       "Q 3003 894 3003 1313 \n",
       "Q 3003 1734 2745 1975 \n",
       "Q 2488 2216 2034 2216 \n",
       "z\n",
       "M 1403 2484 \n",
       "Q 997 2584 770 2862 \n",
       "Q 544 3141 544 3541 \n",
       "Q 544 4100 942 4425 \n",
       "Q 1341 4750 2034 4750 \n",
       "Q 2731 4750 3128 4425 \n",
       "Q 3525 4100 3525 3541 \n",
       "Q 3525 3141 3298 2862 \n",
       "Q 3072 2584 2669 2484 \n",
       "Q 3125 2378 3379 2068 \n",
       "Q 3634 1759 3634 1313 \n",
       "Q 3634 634 3220 271 \n",
       "Q 2806 -91 2034 -91 \n",
       "Q 1263 -91 848 271 \n",
       "Q 434 634 434 1313 \n",
       "Q 434 1759 690 2068 \n",
       "Q 947 2378 1403 2484 \n",
       "z\n",
       "M 1172 3481 \n",
       "Q 1172 3119 1398 2916 \n",
       "Q 1625 2713 2034 2713 \n",
       "Q 2441 2713 2670 2916 \n",
       "Q 2900 3119 2900 3481 \n",
       "Q 2900 3844 2670 4047 \n",
       "Q 2441 4250 2034 4250 \n",
       "Q 1625 4250 1398 4047 \n",
       "Q 1172 3844 1172 3481 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"345.899522\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(330.629522 212.619875) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- Length -->\n",
       "     <g transform=\"translate(195.49 228.233625) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4c\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 531 \n",
       "L 3531 531 \n",
       "L 3531 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \n",
       "Q 2906 2416 2648 2759 \n",
       "Q 2391 3103 1925 3103 \n",
       "Q 1463 3103 1205 2759 \n",
       "Q 947 2416 947 1791 \n",
       "Q 947 1169 1205 825 \n",
       "Q 1463 481 1925 481 \n",
       "Q 2391 481 2648 825 \n",
       "Q 2906 1169 2906 1791 \n",
       "z\n",
       "M 3481 434 \n",
       "Q 3481 -459 3084 -895 \n",
       "Q 2688 -1331 1869 -1331 \n",
       "Q 1566 -1331 1297 -1286 \n",
       "Q 1028 -1241 775 -1147 \n",
       "L 775 -588 \n",
       "Q 1028 -725 1275 -790 \n",
       "Q 1522 -856 1778 -856 \n",
       "Q 2344 -856 2625 -561 \n",
       "Q 2906 -266 2906 331 \n",
       "L 2906 616 \n",
       "Q 2728 306 2450 153 \n",
       "Q 2172 0 1784 0 \n",
       "Q 1141 0 747 490 \n",
       "Q 353 981 353 1791 \n",
       "Q 353 2603 747 3093 \n",
       "Q 1141 3584 1784 3584 \n",
       "Q 2172 3584 2450 3431 \n",
       "Q 2728 3278 2906 2969 \n",
       "L 2906 3500 \n",
       "L 3481 3500 \n",
       "L 3481 434 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \n",
       "L 1172 3500 \n",
       "L 2356 3500 \n",
       "L 2356 3053 \n",
       "L 1172 3053 \n",
       "L 1172 1153 \n",
       "Q 1172 725 1289 603 \n",
       "Q 1406 481 1766 481 \n",
       "L 2356 481 \n",
       "L 2356 0 \n",
       "L 1766 0 \n",
       "Q 1100 0 847 248 \n",
       "Q 594 497 594 1153 \n",
       "L 594 3053 \n",
       "L 172 3053 \n",
       "L 172 3500 \n",
       "L 594 3500 \n",
       "L 594 4494 \n",
       "L 1172 4494 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \n",
       "L 3513 0 \n",
       "L 2938 0 \n",
       "L 2938 2094 \n",
       "Q 2938 2591 2744 2837 \n",
       "Q 2550 3084 2163 3084 \n",
       "Q 1697 3084 1428 2787 \n",
       "Q 1159 2491 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 2956 \n",
       "Q 1366 3272 1645 3428 \n",
       "Q 1925 3584 2291 3584 \n",
       "Q 2894 3584 3203 3211 \n",
       "Q 3513 2838 3513 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"53.962891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"115.486328\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"178.865234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"242.341797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"281.550781\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path id=\"m48aafd2f3e\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"60.35375\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(45.71875 201.060812) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"60.35375\" y=\"157.10833\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 1000 -->\n",
       "      <g transform=\"translate(22.81375 161.667393) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"60.35375\" y=\"117.71491\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 2000 -->\n",
       "      <g transform=\"translate(22.81375 122.273973) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"60.35375\" y=\"78.32149\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 3000 -->\n",
       "      <g transform=\"translate(22.81375 82.880553) scale(0.12 -0.12)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-33\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"60.35375\" y=\"38.92807\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 4000 -->\n",
       "      <g transform=\"translate(22.81375 43.487133) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- Count -->\n",
       "     <g transform=\"translate(16.318125 128.139875) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-43\" d=\"M 4122 4306 \n",
       "L 4122 3641 \n",
       "Q 3803 3938 3442 4084 \n",
       "Q 3081 4231 2675 4231 \n",
       "Q 1875 4231 1450 3742 \n",
       "Q 1025 3253 1025 2328 \n",
       "Q 1025 1406 1450 917 \n",
       "Q 1875 428 2675 428 \n",
       "Q 3081 428 3442 575 \n",
       "Q 3803 722 4122 1019 \n",
       "L 4122 359 \n",
       "Q 3791 134 3420 21 \n",
       "Q 3050 -91 2638 -91 \n",
       "Q 1578 -91 968 557 \n",
       "Q 359 1206 359 2328 \n",
       "Q 359 3453 968 4101 \n",
       "Q 1578 4750 2638 4750 \n",
       "Q 3056 4750 3426 4639 \n",
       "Q 3797 4528 4122 4306 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \n",
       "Q 1497 3097 1228 2736 \n",
       "Q 959 2375 959 1747 \n",
       "Q 959 1119 1226 758 \n",
       "Q 1494 397 1959 397 \n",
       "Q 2419 397 2687 759 \n",
       "Q 2956 1122 2956 1747 \n",
       "Q 2956 2369 2687 2733 \n",
       "Q 2419 3097 1959 3097 \n",
       "z\n",
       "M 1959 3584 \n",
       "Q 2709 3584 3137 3096 \n",
       "Q 3566 2609 3566 1747 \n",
       "Q 3566 888 3137 398 \n",
       "Q 2709 -91 1959 -91 \n",
       "Q 1206 -91 779 398 \n",
       "Q 353 888 353 1747 \n",
       "Q 353 2609 779 3096 \n",
       "Q 1206 3584 1959 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-43\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6f\" x=\"69.824219\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"131.005859\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"194.384766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"257.763672\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 60.35375 196.50175 \n",
       "L 60.35375 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 372.01875 196.50175 \n",
       "L 372.01875 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 60.35375 196.50175 \n",
       "L 372.01875 196.50175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 60.35375 24.14175 \n",
       "L 372.01875 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <!-- Dialogue Token Length -->\n",
       "    <g transform=\"translate(134.36725 18.14175) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-44\" d=\"M 1259 4147 \n",
       "L 1259 519 \n",
       "L 2022 519 \n",
       "Q 2988 519 3436 956 \n",
       "Q 3884 1394 3884 2338 \n",
       "Q 3884 3275 3436 3711 \n",
       "Q 2988 4147 2022 4147 \n",
       "L 1259 4147 \n",
       "z\n",
       "M 628 4666 \n",
       "L 1925 4666 \n",
       "Q 3281 4666 3915 4102 \n",
       "Q 4550 3538 4550 2338 \n",
       "Q 4550 1131 3912 565 \n",
       "Q 3275 0 1925 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \n",
       "Q 1497 1759 1228 1600 \n",
       "Q 959 1441 959 1056 \n",
       "Q 959 750 1161 570 \n",
       "Q 1363 391 1709 391 \n",
       "Q 2188 391 2477 730 \n",
       "Q 2766 1069 2766 1631 \n",
       "L 2766 1759 \n",
       "L 2194 1759 \n",
       "z\n",
       "M 3341 1997 \n",
       "L 3341 0 \n",
       "L 2766 0 \n",
       "L 2766 531 \n",
       "Q 2569 213 2275 61 \n",
       "Q 1981 -91 1556 -91 \n",
       "Q 1019 -91 701 211 \n",
       "Q 384 513 384 1019 \n",
       "Q 384 1609 779 1909 \n",
       "Q 1175 2209 1959 2209 \n",
       "L 2766 2209 \n",
       "L 2766 2266 \n",
       "Q 2766 2663 2505 2880 \n",
       "Q 2244 3097 1772 3097 \n",
       "Q 1472 3097 1187 3025 \n",
       "Q 903 2953 641 2809 \n",
       "L 641 3341 \n",
       "Q 956 3463 1253 3523 \n",
       "Q 1550 3584 1831 3584 \n",
       "Q 2591 3584 2966 3190 \n",
       "Q 3341 2797 3341 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \n",
       "L 3928 4666 \n",
       "L 3928 4134 \n",
       "L 2272 4134 \n",
       "L 2272 0 \n",
       "L 1638 0 \n",
       "L 1638 4134 \n",
       "L -19 4134 \n",
       "L -19 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6b\" d=\"M 581 4863 \n",
       "L 1159 4863 \n",
       "L 1159 1991 \n",
       "L 2875 3500 \n",
       "L 3609 3500 \n",
       "L 1753 1863 \n",
       "L 3688 0 \n",
       "L 2938 0 \n",
       "L 1159 1709 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-44\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-69\" x=\"77.001953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"104.785156\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6c\" x=\"166.064453\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"193.847656\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"255.029297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"318.505859\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"381.884766\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"443.408203\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-54\" x=\"475.195312\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"519.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"580.460938\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"634.746094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"696.269531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"759.648438\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-4c\" x=\"791.435547\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"845.398438\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"906.921875\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"970.300781\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1033.777344\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"1072.986328\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 388.47875 196.50175 \n",
       "L 700.14375 196.50175 \n",
       "L 700.14375 24.14175 \n",
       "L 388.47875 24.14175 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 402.645341 196.50175 \n",
       "L 416.811932 196.50175 \n",
       "L 416.811932 195.359341 \n",
       "L 402.645341 195.359341 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 416.811932 196.50175 \n",
       "L 430.978523 196.50175 \n",
       "L 430.978523 165.656702 \n",
       "L 416.811932 165.656702 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 430.978523 196.50175 \n",
       "L 445.145114 196.50175 \n",
       "L 445.145114 122.520907 \n",
       "L 430.978523 122.520907 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 445.145114 196.50175 \n",
       "L 459.311705 196.50175 \n",
       "L 459.311705 112.002864 \n",
       "L 445.145114 112.002864 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_32\">\n",
       "    <path d=\"M 459.311705 196.50175 \n",
       "L 473.478295 196.50175 \n",
       "L 473.478295 116.966435 \n",
       "L 459.311705 116.966435 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_33\">\n",
       "    <path d=\"M 473.478295 196.50175 \n",
       "L 487.644886 196.50175 \n",
       "L 487.644886 129.651116 \n",
       "L 473.478295 129.651116 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_34\">\n",
       "    <path d=\"M 487.644886 196.50175 \n",
       "L 501.811477 196.50175 \n",
       "L 501.811477 140.090373 \n",
       "L 487.644886 140.090373 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_35\">\n",
       "    <path d=\"M 501.811477 196.50175 \n",
       "L 515.978068 196.50175 \n",
       "L 515.978068 149.702367 \n",
       "L 501.811477 149.702367 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_36\">\n",
       "    <path d=\"M 515.978068 196.50175 \n",
       "L 530.144659 196.50175 \n",
       "L 530.144659 161.165852 \n",
       "L 515.978068 161.165852 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_37\">\n",
       "    <path d=\"M 530.144659 196.50175 \n",
       "L 544.31125 196.50175 \n",
       "L 544.31125 174.126287 \n",
       "L 530.144659 174.126287 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_38\">\n",
       "    <path d=\"M 544.31125 196.50175 \n",
       "L 558.477841 196.50175 \n",
       "L 558.477841 174.638402 \n",
       "L 544.31125 174.638402 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_39\">\n",
       "    <path d=\"M 558.477841 196.50175 \n",
       "L 572.644432 196.50175 \n",
       "L 572.644432 179.405006 \n",
       "L 558.477841 179.405006 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_40\">\n",
       "    <path d=\"M 572.644432 196.50175 \n",
       "L 586.811023 196.50175 \n",
       "L 586.811023 183.817069 \n",
       "L 572.644432 183.817069 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_41\">\n",
       "    <path d=\"M 586.811023 196.50175 \n",
       "L 600.977614 196.50175 \n",
       "L 600.977614 185.78674 \n",
       "L 586.811023 185.78674 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_42\">\n",
       "    <path d=\"M 600.977614 196.50175 \n",
       "L 615.144205 196.50175 \n",
       "L 615.144205 188.938213 \n",
       "L 600.977614 188.938213 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_43\">\n",
       "    <path d=\"M 615.144205 196.50175 \n",
       "L 629.310795 196.50175 \n",
       "L 629.310795 190.63213 \n",
       "L 615.144205 190.63213 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_44\">\n",
       "    <path d=\"M 629.310795 196.50175 \n",
       "L 643.477386 196.50175 \n",
       "L 643.477386 192.562408 \n",
       "L 629.310795 192.562408 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_45\">\n",
       "    <path d=\"M 643.477386 196.50175 \n",
       "L 657.643977 196.50175 \n",
       "L 657.643977 194.374505 \n",
       "L 643.477386 194.374505 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_46\">\n",
       "    <path d=\"M 657.643977 196.50175 \n",
       "L 671.810568 196.50175 \n",
       "L 671.810568 195.832062 \n",
       "L 657.643977 195.832062 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_47\">\n",
       "    <path d=\"M 671.810568 196.50175 \n",
       "L 685.977159 196.50175 \n",
       "L 685.977159 196.462357 \n",
       "L 671.810568 196.462357 \n",
       "z\n",
       "\" clip-path=\"url(#p9d66fb493a)\" style=\"fill: #0071bc; stroke: #0071bc; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"395.380422\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(391.562922 212.619875) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"468.029607\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(460.394607 212.619875) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"540.678791\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_17\">\n",
       "      <!-- 40 -->\n",
       "      <g transform=\"translate(533.043791 212.619875) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-34\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"613.327975\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 60 -->\n",
       "      <g transform=\"translate(605.692975 212.619875) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-36\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m884eb71afe\" x=\"685.977159\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 80 -->\n",
       "      <g transform=\"translate(678.342159 212.619875) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-38\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_20\">\n",
       "     <!-- Length -->\n",
       "     <g transform=\"translate(523.615 228.233625) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#DejaVuSans-4c\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"53.962891\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-6e\" x=\"115.486328\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-67\" x=\"178.865234\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-74\" x=\"242.341797\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-68\" x=\"281.550781\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"388.47875\" y=\"196.50175\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"388.47875\" y=\"157.10833\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"388.47875\" y=\"117.71491\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"388.47875\" y=\"78.32149\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m48aafd2f3e\" x=\"388.47875\" y=\"38.92807\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_48\">\n",
       "    <path d=\"M 388.47875 196.50175 \n",
       "L 388.47875 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_49\">\n",
       "    <path d=\"M 700.14375 196.50175 \n",
       "L 700.14375 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_50\">\n",
       "    <path d=\"M 388.47875 196.50175 \n",
       "L 700.14375 196.50175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_51\">\n",
       "    <path d=\"M 388.47875 24.14175 \n",
       "L 700.14375 24.14175 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- Summary Token Length -->\n",
       "    <g transform=\"translate(459.624625 18.14175) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \n",
       "L 3425 3897 \n",
       "Q 3066 4069 2747 4153 \n",
       "Q 2428 4238 2131 4238 \n",
       "Q 1616 4238 1336 4038 \n",
       "Q 1056 3838 1056 3469 \n",
       "Q 1056 3159 1242 3001 \n",
       "Q 1428 2844 1947 2747 \n",
       "L 2328 2669 \n",
       "Q 3034 2534 3370 2195 \n",
       "Q 3706 1856 3706 1288 \n",
       "Q 3706 609 3251 259 \n",
       "Q 2797 -91 1919 -91 \n",
       "Q 1588 -91 1214 -16 \n",
       "Q 841 59 441 206 \n",
       "L 441 856 \n",
       "Q 825 641 1194 531 \n",
       "Q 1563 422 1919 422 \n",
       "Q 2459 422 2753 634 \n",
       "Q 3047 847 3047 1241 \n",
       "Q 3047 1584 2836 1778 \n",
       "Q 2625 1972 2144 2069 \n",
       "L 1759 2144 \n",
       "Q 1053 2284 737 2584 \n",
       "Q 422 2884 422 3419 \n",
       "Q 422 4038 858 4394 \n",
       "Q 1294 4750 2059 4750 \n",
       "Q 2388 4750 2728 4690 \n",
       "Q 3069 4631 3425 4513 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \n",
       "Q 3544 3216 3844 3400 \n",
       "Q 4144 3584 4550 3584 \n",
       "Q 5097 3584 5394 3201 \n",
       "Q 5691 2819 5691 2113 \n",
       "L 5691 0 \n",
       "L 5113 0 \n",
       "L 5113 2094 \n",
       "Q 5113 2597 4934 2840 \n",
       "Q 4756 3084 4391 3084 \n",
       "Q 3944 3084 3684 2787 \n",
       "Q 3425 2491 3425 1978 \n",
       "L 3425 0 \n",
       "L 2847 0 \n",
       "L 2847 2094 \n",
       "Q 2847 2600 2669 2842 \n",
       "Q 2491 3084 2119 3084 \n",
       "Q 1678 3084 1418 2786 \n",
       "Q 1159 2488 1159 1978 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1356 3278 1631 3431 \n",
       "Q 1906 3584 2284 3584 \n",
       "Q 2666 3584 2933 3390 \n",
       "Q 3200 3197 3328 2828 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-75\" x=\"63.476562\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"126.855469\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6d\" x=\"224.267578\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-61\" x=\"321.679688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-72\" x=\"382.958984\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-79\" x=\"424.072266\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"483.251953\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-54\" x=\"515.039062\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6f\" x=\"559.123047\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6b\" x=\"620.304688\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"674.589844\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"736.113281\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-20\" x=\"799.492188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-4c\" x=\"831.279297\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-65\" x=\"885.242188\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-6e\" x=\"946.765625\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-67\" x=\"1010.144531\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-74\" x=\"1073.621094\"/>\n",
       "     <use xlink:href=\"#DejaVuSans-68\" x=\"1112.830078\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pb0c5c056da\">\n",
       "   <rect x=\"60.35375\" y=\"24.14175\" width=\"311.665\" height=\"172.36\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p9d66fb493a\">\n",
       "   <rect x=\"388.47875\" y=\"24.14175\" width=\"311.665\" height=\"172.36\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x350 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"][\"dialogue\"]]\n",
    "s_len = [len(tokenizer.encode(s)) for s in dataset_samsum[\"train\"]['summary']]\n",
    "\n",
    "# sharey=True: 여러개의 하위 플롯 간에 X축과 Y축을 공유\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3.5), sharey=True)\n",
    "axes[0].hist(d_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[0].set_title(\"Dialogue Token Length\")\n",
    "axes[0].set_xlabel(\"Length\")\n",
    "axes[0].set_ylabel(\"Count\")\n",
    "axes[1].hist(s_len, bins=20, color=\"C0\", edgecolor=\"C0\")\n",
    "axes[1].set_title(\"Summary Token Length\")\n",
    "axes[1].set_xlabel(\"Length\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2480ae",
   "metadata": {},
   "source": [
    "대부분의 대화는 100\\~200개 토큰으로 구성되며 CNN/DailyMail 기사보다 훨씬 더 짧다.  \n",
    "마찬가지로 요약도 20~40개 토큰(평균 트윗 길이)로 구성되며 훨씬 더 짧다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233c9ca4",
   "metadata": {},
   "source": [
    "#### 이런 점을 유념하면서 Trainer를 위한 데이터 콜레이터를 만들어보자.  \n",
    "먼저 데이터셋을 토큰화한다.  \n",
    "여기서는 대화와 요약의 최대길이를 각각 1024와 128로 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a2f84f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(example_batch):\n",
    "    input_encodings = tokenizer(example_batch[\"dialogue\"], max_length=1024,\n",
    "                               truncation=True) # truncation=True : 문장 잘림을 허용\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        target_encodings = tokenizer(example_batch[\"summary\"], max_length=128,\n",
    "                                    truncation=True)\n",
    "    \n",
    "    return {\"input_ids\": input_encodings[\"input_ids\"],\n",
    "           \"attention_mask\": input_encodings[\"attention_mask\"],\n",
    "           \"labels\": target_encodings[\"input_ids\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea35ab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_samsum_pt = dataset_samsum.map(convert_examples_to_features,\n",
    "                                      batched=True) # batched=True: 적용되는 함수가 배치형태로 처리가 가능한 함수인 경우에 체크. 멀티 쓰레딩을 사용해 텍스트 데이터를 배치 형태로 빠르게 처리할 수 있습니다.\n",
    "columns = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "dataset_samsum_pt.set_format(type=\"torch\", columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5a6bb",
   "metadata": {},
   "source": [
    "토큰화 단계에 새롭게 적용한 것 -> tokenizer.as_target_tokenizer()  \n",
    "일부 모델은 디코더 입력에 특수 토큰이 필요하다.  \n",
    "따라서 인코더와 디코더 입력의 토큰화를 구별하는 것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af30945",
   "metadata": {},
   "source": [
    "#### 컨텍스트 매니저 (context manager)라 부르는 with 문을 사용하면 토크나이저가 디코더를 위한 토큰화임을 인지하고 그에 따라 시퀀스를 처리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f364ef00",
   "metadata": {},
   "source": [
    "### 이제 데이터 콜레이터를 만들어 보자. (데이터 콜레이터는 샘플 목록을 가져와 일괄 처리로 변환하는 함수)\n",
    "이 함수는 배치를 모델에 주입하기 전에 Trainer에 의해 호출된다.  \n",
    "대부분의 경우 단순히 배치에 있는 모든 텐서를 가져와 쌓는 기본 콜레이터를 사용한다.  \n",
    "#### 요약 작업에서는 입력을 쌓을 뿐만 아니라 디코더 쪽의 타깃도 준비한다.  \n",
    "PEGASUS는 인코더-디코더 트랜스포머이고, 따라서 고전적인 seq2seq 구조를 취한다.  \n",
    "seq2seq 구조에서는 디코더에 '티처 포싱 teacher forcing'을 적용하는 것이 일반적이다.  \n",
    "  \n",
    "(teacher forcing: 디코더의 다음 타임스텝에 입력값으로, 이전 타임스텝의 결과값이 아닌 정답값을 넣어 학습하는 형태)  \n",
    "이 전략에서는 (GPT-2 등의 디코더 전용 모델처럼) 디코더가 인코더 출력 외에 한 토큰이 이동된 레이블로 구성된 입력 토큰을 받는다.  \n",
    "따라서 아래 표처럼 다음 토큰을 위한 예측을 만들 때 디코더는 한 토큰이 이동된 정답을 입력으로 받는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a41b9f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[PAD]</td>\n",
       "      <td>Transformers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[PAD, Transformers]</td>\n",
       "      <td>are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[PAD, Transformers, are]</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[PAD, Transformers, are, awesome]</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for]</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[PAD, Transformers, are, awesome, for, text]</td>\n",
       "      <td>summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     decoder_input          label\n",
       "step                                                             \n",
       "1                                            [PAD]   Transformers\n",
       "2                              [PAD, Transformers]            are\n",
       "3                         [PAD, Transformers, are]        awesome\n",
       "4                [PAD, Transformers, are, awesome]            for\n",
       "5           [PAD, Transformers, are, awesome, for]           text\n",
       "6     [PAD, Transformers, are, awesome, for, text]  summarization"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 티처 포싱(teacher forcing)\n",
    "# 텍스트 생성을 위한 디코더 입력과 레이블의 정렬\n",
    "text = ['PAD','Transformers', 'are', 'awesome', 'for', 'text', 'summarization']\n",
    "rows = []\n",
    "for i in range(len(text)-1): # 이러면 i가 text의 index\n",
    "    rows.append({'step': i+1, 'decoder_input': text[:i+1], 'label': text[i+1]})\n",
    "pd.DataFrame(rows).set_index('step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70215f2",
   "metadata": {},
   "source": [
    "한 스텝 이동했으므로 디코더는 이전 스텝의 정답 레이블만 보며 현재와 미래의 레이블을 보지 못한다.  \n",
    "디코더는 현재와 미래의 모든 입력을 마스킹하는 마스크드 셀프 어텐션을 갖기 때문에 이동시키는 것으로 충분하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a635b",
   "metadata": {},
   "source": [
    "따라서 배치를 준비할 때 레이블을 한 스텝 오른쪽으로 이동시켜 디코더 입력을 만든다.  \n",
    "그런 다음 레이블에 있는 패딩 토큰을 -100으로 설정해 손실 함수가 무시하도록 만든다.  \n",
    "그러나 DataCollatorForSeq2Seq에서 이런 작업을 모두 처리하므로 실제로 이를 수동으로 할 필요는 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6a66b9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94463ff5",
   "metadata": {},
   "source": [
    "#### 이제 이전처럼 훈련을 위해 TrainingArguments를 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ec79cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
    "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
    "    weight_decay=0.01, logging_steps=10, push_to_hub=True,\n",
    "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
    "    gradient_accumulation_steps=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79209651",
   "metadata": {},
   "source": [
    "이전과 달리 새 매개변수 gradient_accumulation_steps가 추가됐다.  \n",
    "#### 모델이 매우 크니 배치 크기를 1로 지정하는데, 배치 크기가 너무 작으면 수렴하지 않는다.  \n",
    "#### 이 문제를 해결하기 위해 그레디언트 누적(gradient accumulation)이라는 기술을 사용한다.\n",
    "이름 그대로 큰 배치의 그레디언트를 한 번에 계산하는 대신 작은 배치를 만들고 그레디언트를 누적하는 방식이다.  \n",
    "그레디언트가 충분히 누적되면 최적화 단계가 수행된다.  \n",
    "### 당연히 한 번에 실행하는 것보다 조금 더 느리지만 GPU 메모리가 많이 절약된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6b9f1216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2cb90c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd4a9229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jj/github/NLP/nlp-with-transformers/pegasus-samsum is already a clone of https://huggingface.co/bh8648/pegasus-samsum. Make sure you pull the latest changes with `repo.git_pull()`.\n",
      "WARNING:huggingface_hub.repository:/home/jj/github/NLP/nlp-with-transformers/pegasus-samsum is already a clone of https://huggingface.co/bh8648/pegasus-samsum. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=training_args,\n",
    "                 tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
    "                 train_dataset=dataset_samsum_pt[\"train\"],\n",
    "                 eval_dataset=dataset_samsum_pt[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba6eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae899ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = evaluate_summaries_pegasus(\n",
    "    dataset_samsum[\"test\"], rouge_metric, trainer.model, tokenizer,\n",
    "    batch_size=1, column_text=\"dialogue\", column_summary=\"summary\")\n",
    "\n",
    "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
    "pd.DataFrame(rouge_dict, index=[f\"pegasus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77422122",
   "metadata": {},
   "source": [
    "훈련 루프의 일부로 생성된 텍스트를 평가할 수도 있다.  \n",
    "Seq2SeqTrainingArguments란 이름의 TrainingArguments의 확장을 사용하고 predict_with_generate=True를 지정한다.  \n",
    "이를 Seq2SeqTrainer란 이름의 전용 Trainer에 전달한다.  \n",
    "그러면 평가를 위해 모델의 정방향 패스가 아니라 generate() 함수를 사용해 예측을 만든다.  \n",
    "한 번 실험해 볼 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2982fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b427a",
   "metadata": {},
   "source": [
    "## 6.6.3 대화 요약 생성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51052309",
   "metadata": {},
   "source": [
    "테스트 세트에 있는 샘플로 어떤 요약이 만들어지는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c82a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "transformers.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc623fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\": 8, \"max_length\": 128}\n",
    "sample_text = dataset_samsum[\"test\"][0][\"dialogue\"]\n",
    "reference = dataset_samsum[\"test\"][0][\"summary\"]\n",
    "# `bh8648`를 자신의 허브 사용자 이름으로 바꾸세요.\n",
    "pipe = pipeline(\"summarization\", model=\"bh8648/pegasus-samsum\")\n",
    "\n",
    "print(\"대화:\")\n",
    "print(sample_text)\n",
    "print(\"\\n참조 요약:\")\n",
    "print(reference)\n",
    "print(\"\\n모델 요약:\")\n",
    "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854d201",
   "metadata": {},
   "source": [
    "진짜 테스흐 -> 실제 대화 입력에서 이 모델이 얼마나 잘 동작할까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27af2666",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dialogue = \"\"\"\\\n",
    "Thom: Hi guys, have you heard of transformers?\n",
    "Lewis: Yes, I used them recently!\n",
    "Leandro: Indeed, there is a great library by Hugging Face.\n",
    "Thom: I know, I helped build it ;)\n",
    "Lewis: Cool, maybe we should write a book about it. What do you think?\n",
    "Leandro: Great idea, how hard can it be?!\n",
    "Thom: I am in!\n",
    "Lewis: Awesome, let's do it together!\n",
    "\"\"\"\n",
    "print(pipe(custom_dialogue, **gen_kwargs)[0][\"summary_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c498a45d",
   "metadata": {},
   "source": [
    "# 6.7 결론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07338ce",
   "metadata": {},
   "source": [
    "텍스트 요약은 감성 분석, 개체명 인식, 질문 답변과 같이 분류 작업으로 구성되는 작업에 비해 특수한 어려움이 몇가지 있다.  \n",
    "정확도 같은 전통적인 지표는 텍스트의 품질을 반영하지 못한다.  \n",
    "이 장에서 보았듯이 BLEU와 ROUGE 지표가 생성된 텍스트를 더 잘 평가한다.  \n",
    "하지만 여전히 사람의 판단이 가장 좋은 척도다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907626ee",
   "metadata": {},
   "source": [
    "요약 모델로 작업할 때는 주로 모델의 문맥 크기보다 긴 텍스트를 어떻게 요약할지에 의문이 생긴다.  \n",
    "안타깝게도 이 문제를 해결할 수 있는 단일 전략은 없다.  \n",
    "아직까지도 활발하게 연구되고 있는 미결의 문제다.  \n",
    "OpenAI에서는 긴 문서에 반복적으로 모델을 적용하고 사람의 피드백을 반복 루프에 추가해 요약 작업의 스케일을 확장했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe58552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a22c0b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10063297536"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3566bc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11291066368"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_reserved() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "504ca197",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() # torch.cuda.empty_cache()는 torch.cuda.memory_reserved() 에서 보이는 만큼을 free하게 해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ed03ff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "\n",
    "a = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a8017f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'NVIDIA GeForce GTX 1080 Ti''>\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cc918583",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fde218",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
